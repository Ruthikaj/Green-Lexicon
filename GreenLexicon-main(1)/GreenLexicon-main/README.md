# GreenLexicon

## Introduction

GreenLexicon is a comprehensive platform designed to promote sustainability and environmental awareness. It leverages advanced data analytics, natural language processing (NLP), and computer vision technologies to empower users with actionable insights and tools for making eco-friendly decisions.

## [Power Point Presentation](https://docs.google.com/presentation/d/1D0pjO6HqTgpijJablJLPavPj83ef0WSP/edit?usp=sharing&ouid=115204430181103761560&rtpof=true&sd=true)

## Recognization and Awards

My team, Mavericks, 
## To Know More About Our Project

## Key Features

1. **[Energy Consumption Analysis (Data Analytics):](https://github.com/GunaPalanivel/energyanalyzer.git)**

   - Provides users with a personalized dashboard to identify energy consumption patterns, pinpoint inefficiencies, and encourage energy-saving habits.

2. **[Amazon Product Sustainability Score (NLP+LLM, BERT Model):](https://github.com/GunaPalanivel/sustainablescore.git)**

   - An AI-driven scoring system that analyzes product descriptions to calculate a sustainability score, utilizing state-of-the-art NLP techniques and the BERT language model.

3. **[Lexicon AI Using Gemini API:](https://github.com/GunaPalanivel/Lexicon-AI.git)**

   - Experience the simplicity of Lexicon AI, a minimalistic web interface designed to enhance your communication needs.

4. **[Brand Sustainability Profiles (LLM, Web Scraping):](https://github.com/GunaPalanivel/sustainablebrands.git)**

   - Compiles data on corporate sustainability practices through advanced Large Language Model (LLM) capabilities and web scraping, offering concise brand sustainability profiles.

5. **[Green Lexicon AI Chatbot:](https://github.com/GunaPalanivel/GreenLexicon-Chat-Bot.git)**

   - A seamless experience as you explore answers to all your questions about sustainability and environmental consciousness

6. **[Waste Classification Guide (Computer Vision, CNN, TensorflowJs):](https://github.com/GunaPalanivel/gitpod.git)**
   - A user-friendly guide that incorporates a custom-trained Convolutional Neural Network (CNN) to identify and sort waste, promoting correct disposal procedures and environmental conservation.

## Tech Stack

- Front-end: HTML5, CSS3, JavaScript
- Back-end: Python, Streamlit
- Data Analytics: Pandas, NumPy, Matplotlib
- NLP and LLM: BERT, Gemini
- Computer Vision: TensorFlow.js, Convolutional Neural Networks (CNN)

## Quick Links

- [Live Website](https://green-lexicon.vercel.app/)
- [Main GitHub Repository](https://github.com/Ruthika/GreenLexicon.git)
- [Image Detection Custom Model (Google Colab)]()
- [NLP Sustainability Model (BERT) Google Colab]()
- [Project Image Gallery](https://green-lexicon-image-gallery.vercel.app/)

## Usage

1. Clone the repository:
   ```shell
   https://github.com/Ruthika/GreenLexicon.git
   ```
   ```shell
   cd GreenLexicon
   ```
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. Run the Streamlit app:
   ```bash
   streamlit run Hello.py
   ```
4. Refer to the Google Colab notebooks for the custom CNN implementation and the NLP BERT model usage.

## How to Contribute

Contributions are welcome! If you would like to contribute to this project, please follow these steps:

1. Fork the repository.
2. Create a new branch: `git checkout -b feature/new-feature`.
3. Make your changes and commit them: `git commit -m 'Add new feature'`.
4. Push to the branch: `git push origin feature/new-feature`.
5. Submit a pull request.


